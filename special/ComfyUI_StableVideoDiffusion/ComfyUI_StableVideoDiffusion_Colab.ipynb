{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaaaaaaaaa"
      },
      "source": [
        "# 説明\n",
        "\n",
        "*注意：Google Colab Pro/Pro+で使用してください。無料版Colabでは画像生成AIの使用が規制されています。\n",
        "\n",
        "- これはComfyUIでStable VideoDiffusionを手軽に利用するためのColabです。\n",
        "- 以下の各セルを順に実行してください。3番目のセルを実行後、表示されるリンクをクリックするとComfyUIが起動します\n",
        "- cloudflaredが不安定でURLが開かない場は、時間をおいて試すか4番目の予備のセル（local tunnelによる起動）をお試しください。\n",
        "\n",
        "\n",
        "*Note: This Colab should be used with Google Colab Pro/Pro+. The free version of Colab restricts the use of ComfyUI.\n",
        "\n",
        "- For easy use of Stable Video Diffusion with ComfyUI.\n",
        "- Run each cell below in order; while running the third cell, click on the link that appears to start ComfyUI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6oQao_HfMMgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd62eaa6-f169-426b-8380-3053f9f8f199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-= Initial setup ComfyUI =-\n",
            "Cloning into 'ComfyUI'...\n",
            "remote: Enumerating objects: 8704, done.\u001b[K\n",
            "remote: Counting objects: 100% (3349/3349), done.\u001b[K\n",
            "remote: Compressing objects: 100% (309/309), done.\u001b[K\n",
            "remote: Total 8704 (delta 3128), reused 3080 (delta 3040), pack-reused 5355\u001b[K\n",
            "Receiving objects: 100% (8704/8704), 3.49 MiB | 6.60 MiB/s, done.\n",
            "Resolving deltas: 100% (5867/5867), done.\n",
            "/content/ComfyUI\n",
            "-= Updating ComfyUI =-\n",
            "Already up to date.\n",
            "-= Install dependencies =-\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu121, https://download.pytorch.org/whl/cu118, https://download.pytorch.org/whl/cu117\n",
            "Collecting xformers!=0.0.18\n",
            "  Downloading https://download.pytorch.org/whl/cu118/xformers-0.0.22.post7%2Bcu118-cp310-cp310-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.1.0+cu118)\n",
            "Collecting torchsde (from -r requirements.txt (line 2))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m970.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from -r requirements.txt (line 3))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.35.2)\n",
            "Requirement already satisfied: safetensors>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.8.6)\n",
            "Collecting accelerate (from -r requirements.txt (line 7))\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (5.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers!=0.0.18) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2.1.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->-r requirements.txt (line 2))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 4)) (0.15.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp->-r requirements.txt (line 6)) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 4)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 4)) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: trampoline, einops, xformers, torchsde, accelerate\n",
            "Successfully installed accelerate-0.24.1 einops-0.7.0 torchsde-0.2.6 trampoline-0.1.2 xformers-0.0.22.post7+cu118\n",
            "/content/ComfyUI/custom_nodes\n",
            "-= Initial setup ComfyUI-Manager =-\n",
            "Cloning into 'ComfyUI-Manager'...\n",
            "remote: Enumerating objects: 3674, done.\u001b[K\n",
            "remote: Counting objects: 100% (1291/1291), done.\u001b[K\n",
            "remote: Compressing objects: 100% (362/362), done.\u001b[K\n",
            "remote: Total 3674 (delta 949), reused 1047 (delta 929), pack-reused 2383\u001b[K\n",
            "Receiving objects: 100% (3674/3674), 3.06 MiB | 6.19 MiB/s, done.\n",
            "Resolving deltas: 100% (2613/2613), done.\n",
            "/content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "Already up to date.\n",
            "/content/ComfyUI\n",
            "/content/ComfyUI\n",
            "-= Install custom nodes dependencies =-\n",
            "## Install dependencies for 'ComfyUI-Manager'\n",
            "Collecting GitPython (from -r custom_nodes/ComfyUI-Manager/requirements.txt (line 1))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matrix-client==0.4.0 (from -r custom_nodes/ComfyUI-Manager/requirements.txt (line 2))\n",
            "  Downloading matrix_client-0.4.0-py2.py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests~=2.22 in /usr/local/lib/python3.10/dist-packages (from matrix-client==0.4.0->-r custom_nodes/ComfyUI-Manager/requirements.txt (line 2)) (2.31.0)\n",
            "Collecting urllib3~=1.21 (from matrix-client==0.4.0->-r custom_nodes/ComfyUI-Manager/requirements.txt (line 2))\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1 (from GitPython->-r custom_nodes/ComfyUI-Manager/requirements.txt (line 1))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython->-r custom_nodes/ComfyUI-Manager/requirements.txt (line 1))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.22->matrix-client==0.4.0->-r custom_nodes/ComfyUI-Manager/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.22->matrix-client==0.4.0->-r custom_nodes/ComfyUI-Manager/requirements.txt (line 2)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.22->matrix-client==0.4.0->-r custom_nodes/ComfyUI-Manager/requirements.txt (line 2)) (2023.7.22)\n",
            "Installing collected packages: urllib3, smmap, gitdb, matrix-client, GitPython\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "Successfully installed GitPython-3.1.40 gitdb-4.0.11 matrix-client-0.4.0 smmap-5.0.1 urllib3-1.26.18\n"
          ]
        }
      ],
      "source": [
        "#@title 環境設定（Environment Setup）\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = False  #@param {type:\"boolean\"}\n",
        "UPDATE_COMFY_UI = True  #@param {type:\"boolean\"}\n",
        "USE_COMFYUI_MANAGER = True  #@param {type:\"boolean\"}\n",
        "INSTALL_CUSTOM_NODES_DEPENDENCIES = True  #@param {type:\"boolean\"}\n",
        "OPTIONS['USE_GOOGLE_DRIVE'] = USE_GOOGLE_DRIVE\n",
        "OPTIONS['UPDATE_COMFY_UI'] = UPDATE_COMFY_UI\n",
        "OPTIONS['USE_COMFYUI_MANAGER'] = USE_COMFYUI_MANAGER\n",
        "OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES'] = INSTALL_CUSTOM_NODES_DEPENDENCIES\n",
        "\n",
        "current_dir = !pwd\n",
        "WORKSPACE = f\"{current_dir[0]}/ComfyUI\"\n",
        "\n",
        "if OPTIONS['USE_GOOGLE_DRIVE']:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    WORKSPACE = \"/content/drive/MyDrive/ComfyUI\"\n",
        "    %cd /content/drive/MyDrive\n",
        "\n",
        "![ ! -d $WORKSPACE ] && echo -= Initial setup ComfyUI =- && git clone https://github.com/comfyanonymous/ComfyUI\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['UPDATE_COMFY_UI']:\n",
        "  !echo -= Updating ComfyUI =-\n",
        "  !git pull\n",
        "\n",
        "!echo -= Install dependencies =-\n",
        "!pip install xformers!=0.0.18 -r requirements.txt --extra-index-url https://download.pytorch.org/whl/cu121 --extra-index-url https://download.pytorch.org/whl/cu118 --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "\n",
        "if OPTIONS['USE_COMFYUI_MANAGER']:\n",
        "  %cd custom_nodes\n",
        "  ![ ! -d ComfyUI-Manager ] && echo -= Initial setup ComfyUI-Manager =- && git clone https://github.com/ltdrdata/ComfyUI-Manager\n",
        "  %cd ComfyUI-Manager\n",
        "  !git pull\n",
        "\n",
        "%cd $WORKSPACE\n",
        "\n",
        "if OPTIONS['INSTALL_CUSTOM_NODES_DEPENDENCIES']:\n",
        "  !pwd\n",
        "  !echo -= Install custom nodes dependencies =-\n",
        "  ![ -f \"custom_nodes/ComfyUI-Manager/scripts/colab-dependencies.py\" ] && python \"custom_nodes/ComfyUI-Manager/scripts/colab-dependencies.py\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dddddddddd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69e44ae7-52fb-472d-db6d-baa2f44f4a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-01 10:22:53--  https://huggingface.co/becausecurious/stable-video-diffusion-img2vid-fp16/resolve/main/svd_xt-fp16.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.4, 18.172.134.88, 18.172.134.24, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.huggingface.co/repos/1b/ad/1bad2203a02264d402d4eb0b9d692df42842f91281bfd92c0db4a684f800853c/8dc27c8419b42767445dc1b3af5371d71b86da0aa7ff31b1ffcc35b94f8b87fe?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27svd_xt-fp16.safetensors%3B+filename%3D%22svd_xt-fp16.safetensors%22%3B&Expires=1701685373&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMTY4NTM3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzFiL2FkLzFiYWQyMjAzYTAyMjY0ZDQwMmQ0ZWIwYjlkNjkyZGY0Mjg0MmY5MTI4MWJmZDkyYzBkYjRhNjg0ZjgwMDg1M2MvOGRjMjdjODQxOWI0Mjc2NzQ0NWRjMWIzYWY1MzcxZDcxYjg2ZGEwYWE3ZmYzMWIxZmZjYzM1Yjk0ZjhiODdmZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=XTH80l5miNzTJxJL-V87mrFk-0-IZg7ZNn--fsiQPQBAXBJxR5V8F3yxtJhIRJpkStNn4RT60OsLTzBQEq-I8Kt3VgRXk8s0%7ES8DO27efFJTkUn7HhPfsmb42Z1INQKoLI2T%7EEHhhyY6Ml4FLKF4InOgGL-00f%7EctDXiRlR3pxkNj7lBeyjvM5I0VswF7ChXWM3yOTXCOZKVUlYEEf%7EnMlSn0L1bZMnjy%7Es1gTbMXgmtP7Ff3H2%7EsvjrMmALRVRxQVFatibU8xarvxzV0uDoevVjvsHjjhuI15fw6dNzO%7EvvwbYPaUQMwXtSEBrgJbfbph-blSgEkjE739Pr31zdww__&Key-Pair-Id=KCD77M1F0VK2B [following]\n",
            "--2023-12-01 10:22:53--  https://cdn-lfs-us-1.huggingface.co/repos/1b/ad/1bad2203a02264d402d4eb0b9d692df42842f91281bfd92c0db4a684f800853c/8dc27c8419b42767445dc1b3af5371d71b86da0aa7ff31b1ffcc35b94f8b87fe?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27svd_xt-fp16.safetensors%3B+filename%3D%22svd_xt-fp16.safetensors%22%3B&Expires=1701685373&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMTY4NTM3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzFiL2FkLzFiYWQyMjAzYTAyMjY0ZDQwMmQ0ZWIwYjlkNjkyZGY0Mjg0MmY5MTI4MWJmZDkyYzBkYjRhNjg0ZjgwMDg1M2MvOGRjMjdjODQxOWI0Mjc2NzQ0NWRjMWIzYWY1MzcxZDcxYjg2ZGEwYWE3ZmYzMWIxZmZjYzM1Yjk0ZjhiODdmZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=XTH80l5miNzTJxJL-V87mrFk-0-IZg7ZNn--fsiQPQBAXBJxR5V8F3yxtJhIRJpkStNn4RT60OsLTzBQEq-I8Kt3VgRXk8s0%7ES8DO27efFJTkUn7HhPfsmb42Z1INQKoLI2T%7EEHhhyY6Ml4FLKF4InOgGL-00f%7EctDXiRlR3pxkNj7lBeyjvM5I0VswF7ChXWM3yOTXCOZKVUlYEEf%7EnMlSn0L1bZMnjy%7Es1gTbMXgmtP7Ff3H2%7EsvjrMmALRVRxQVFatibU8xarvxzV0uDoevVjvsHjjhuI15fw6dNzO%7EvvwbYPaUQMwXtSEBrgJbfbph-blSgEkjE739Pr31zdww__&Key-Pair-Id=KCD77M1F0VK2B\n",
            "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 108.156.107.44, 108.156.107.80, 108.156.107.29, ...\n",
            "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|108.156.107.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4779986098 (4.5G) [binary/octet-stream]\n",
            "Saving to: ‘./models/checkpoints/svd_xt-fp16.safetensors’\n",
            "\n",
            "svd_xt-fp16.safeten 100%[===================>]   4.45G   239MB/s    in 19s     \n",
            "\n",
            "2023-12-01 10:23:12 (242 MB/s) - ‘./models/checkpoints/svd_xt-fp16.safetensors’ saved [4779986098/4779986098]\n",
            "\n",
            "Cloning into 'custom_nodes/ComfyUI-VideoHelperSuite'...\n",
            "remote: Enumerating objects: 847, done.\u001b[K\n",
            "remote: Counting objects: 100% (300/300), done.\u001b[K\n",
            "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
            "remote: Total 847 (delta 186), reused 241 (delta 159), pack-reused 547\u001b[K\n",
            "Receiving objects: 100% (847/847), 213.53 KiB | 2.88 MiB/s, done.\n",
            "Resolving deltas: 100% (385/385), done.\n"
          ]
        }
      ],
      "source": [
        "#@title モデル等のダウンロード（Download some models or custom nodes）\n",
        "\n",
        "# StableVideoDiffusion（fp16版）\n",
        "!wget -c https://huggingface.co/becausecurious/stable-video-diffusion-img2vid-fp16/resolve/main/svd_xt-fp16.safetensors -P ./models/checkpoints/ #XTモデル\n",
        "#!wget -c https://huggingface.co/becausecurious/stable-video-diffusion-img2vid-fp16/resolve/main/svd-fp16.safetensors -P ./models/checkpoints/ #通常モデル\n",
        "\n",
        "# VideoHelperSuite（動画関連補助ツール）\n",
        "!git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git custom_nodes/ComfyUI-VideoHelperSuite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjjjjjjjjjjjjj",
        "outputId": "a51afa3b-6a17-4453-9191-c4ac1c175de2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-01 10:23:13--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2023.10.0/cloudflared-linux-amd64.deb [following]\n",
            "--2023-12-01 10:23:13--  https://github.com/cloudflare/cloudflared/releases/download/2023.10.0/cloudflared-linux-amd64.deb\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/3908a9b9-b0ed-4e7f-9ab0-25185ca66e06?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231201T102313Z&X-Amz-Expires=300&X-Amz-Signature=a9352581c26993a764c8a69f91d984cc3e3ffd833ad3df669c473905a252f826&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-12-01 10:23:13--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/3908a9b9-b0ed-4e7f-9ab0-25185ca66e06?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231201T102313Z&X-Amz-Expires=300&X-Amz-Signature=a9352581c26993a764c8a69f91d984cc3e3ffd833ad3df669c473905a252f826&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106867604&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64.deb&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17717280 (17M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64.deb’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  16.90M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-12-01 10:23:13 (150 MB/s) - ‘cloudflared-linux-amd64.deb’ saved [17717280/17717280]\n",
            "\n",
            "Selecting previously unselected package cloudflared.\n",
            "(Reading database ... 120882 files and directories currently installed.)\n",
            "Preparing to unpack cloudflared-linux-amd64.deb ...\n",
            "Unpacking cloudflared (2023.10.0) ...\n",
            "Setting up cloudflared (2023.10.0) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "** ComfyUI start up time: 2023-12-01 10:23:15.484542\n",
            "\n",
            "Prestartup times for custom nodes:\n",
            "   0.0 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "\n",
            "Total VRAM 15102 MB, total RAM 12983 MB\n",
            "xformers version: 0.0.22.post7+cu118\n",
            "Set vram state to: NORMAL_VRAM\n",
            "Device: cuda:0 Tesla T4 : cudaMallocAsync\n",
            "VAE dtype: torch.float32\n",
            "Using xformers cross attention\n",
            "### Loading: ComfyUI-Manager (V1.5.2)\n",
            "### ComfyUI Revision: 1761 [ec7a00aa] | Released on '2023-12-01'\n",
            "\n",
            "Import times for custom nodes:\n",
            "   0.2 seconds: /content/ComfyUI/custom_nodes/ComfyUI-Manager\n",
            "   0.4 seconds: /content/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite\n",
            "\n",
            "\n",
            "ComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\n",
            "\n",
            "This is the URL to access ComfyUI: https://pair-templates-exclude-expanded.trycloudflare.com                                 |\n",
            "FETCH DATA from: /content/ComfyUI/custom_nodes/ComfyUI-Manager/extension-node-map.json\n",
            "got prompt\n",
            "ERROR:root:Failed to validate prompt for output 33:\n",
            "ERROR:root:* LoadImage 23:\n",
            "ERROR:root:  - Custom validation failed for node: image - Invalid image file: sample_image.jpg\n",
            "ERROR:root:Output will be ignored\n",
            "invalid prompt: {'type': 'prompt_outputs_failed_validation', 'message': 'Prompt outputs failed validation', 'details': '', 'extra_info': {}}\n",
            "got prompt\n",
            "model_type V_PREDICTION_EDM\n",
            "adm 768\n",
            "Using xformers attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using xformers attention in VAE\n",
            "left over keys: dict_keys(['conditioner.embedders.0.open_clip.model.ln_final.bias', 'conditioner.embedders.0.open_clip.model.ln_final.weight', 'conditioner.embedders.0.open_clip.model.logit_scale', 'conditioner.embedders.0.open_clip.model.positional_embedding', 'conditioner.embedders.0.open_clip.model.text_projection', 'conditioner.embedders.0.open_clip.model.token_embedding.weight', 'conditioner.embedders.3.encoder.decoder.conv_in.bias', 'conditioner.embedders.3.encoder.decoder.conv_in.weight', 'conditioner.embedders.3.encoder.decoder.conv_out.bias', 'conditioner.embedders.3.encoder.decoder.conv_out.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.k.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.k.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.norm.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.norm.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.proj_out.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.proj_out.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.q.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.q.weight', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.v.bias', 'conditioner.embedders.3.encoder.decoder.mid.attn_1.v.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.mid.block_2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.mid.block_2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.norm_out.bias', 'conditioner.embedders.3.encoder.decoder.norm_out.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.nin_shortcut.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.nin_shortcut.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.0.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.0.block.2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.nin_shortcut.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.nin_shortcut.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.0.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.1.block.2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.1.upsample.conv.bias', 'conditioner.embedders.3.encoder.decoder.up.1.upsample.conv.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.0.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.2.block.2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.2.upsample.conv.bias', 'conditioner.embedders.3.encoder.decoder.up.2.upsample.conv.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.0.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.1.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.conv1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.conv1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.conv2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.conv2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.norm1.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.norm1.weight', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.norm2.bias', 'conditioner.embedders.3.encoder.decoder.up.3.block.2.norm2.weight', 'conditioner.embedders.3.encoder.decoder.up.3.upsample.conv.bias', 'conditioner.embedders.3.encoder.decoder.up.3.upsample.conv.weight', 'conditioner.embedders.3.encoder.encoder.conv_in.bias', 'conditioner.embedders.3.encoder.encoder.conv_in.weight', 'conditioner.embedders.3.encoder.encoder.conv_out.bias', 'conditioner.embedders.3.encoder.encoder.conv_out.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.0.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.0.block.1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.0.downsample.conv.bias', 'conditioner.embedders.3.encoder.encoder.down.0.downsample.conv.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.nin_shortcut.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.nin_shortcut.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.0.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.1.block.1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.1.downsample.conv.bias', 'conditioner.embedders.3.encoder.encoder.down.1.downsample.conv.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.nin_shortcut.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.nin_shortcut.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.0.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.2.block.1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.2.downsample.conv.bias', 'conditioner.embedders.3.encoder.encoder.down.2.downsample.conv.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.0.norm2.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.down.3.block.1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.k.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.k.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.norm.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.norm.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.proj_out.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.proj_out.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.q.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.q.weight', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.v.bias', 'conditioner.embedders.3.encoder.encoder.mid.attn_1.v.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_1.conv1.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_1.conv1.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_1.conv2.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_1.conv2.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_1.norm1.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_1.norm1.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_1.norm2.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_1.norm2.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_2.conv1.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_2.conv1.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_2.conv2.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_2.conv2.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_2.norm1.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_2.norm1.weight', 'conditioner.embedders.3.encoder.encoder.mid.block_2.norm2.bias', 'conditioner.embedders.3.encoder.encoder.mid.block_2.norm2.weight', 'conditioner.embedders.3.encoder.encoder.norm_out.bias', 'conditioner.embedders.3.encoder.encoder.norm_out.weight', 'conditioner.embedders.3.encoder.post_quant_conv.bias', 'conditioner.embedders.3.encoder.post_quant_conv.weight', 'conditioner.embedders.3.encoder.quant_conv.bias', 'conditioner.embedders.3.encoder.quant_conv.weight'])\n",
            "loaded straight to GPU\n",
            "Requested to load SVD_img2vid\n",
            "Loading 1 new model\n",
            "Requested to load CLIPVisionModelWithProjection\n",
            "Loading 1 new model\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "Requested to load SVD_img2vid\n",
            "Loading 1 new model\n",
            "unload clone 2\n",
            "100% 12/12 [02:52<00:00, 14.38s/it]\n",
            "Requested to load AutoencodingEngine\n",
            "Loading 1 new model\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
            "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
            "Prompt executed in 277.88 seconds\n"
          ]
        }
      ],
      "source": [
        "#@title ComfyUIの起動（Run ComfyUI with cloudflared）\n",
        "\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch cloudflared (if it gets stuck here cloudflared is having issues)\\n\")\n",
        "\n",
        "  p = subprocess.Popen([\"cloudflared\", \"tunnel\", \"--url\", \"http://127.0.0.1:{}\".format(port)], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "  for line in p.stderr:\n",
        "    l = line.decode()\n",
        "    if \"trycloudflare.com \" in l:\n",
        "      print(\"This is the URL to access ComfyUI:\", l[l.find(\"http\"):], end='')\n",
        "    #print(l, end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjjjjjjjjjjjj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title 予備：ComfyUIの起動（Run ComfyUI with localtunnel）表示されたURLをクリックしたら、URLの上に表示されているIPを入力\n",
        "\n",
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}